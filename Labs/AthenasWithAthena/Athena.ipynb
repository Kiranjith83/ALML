{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import time\n",
    "import codecs\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 URI is not required. Just provide bucket name \n",
    "input_bucket = \"<Enter your s3 data bucket name>\"\n",
    "input_prefix = \"how-many-athenas-with-athena/\"\n",
    "output_bucket= \"<Enter your s3 output bucket name>\"\n",
    "output_prefix = \"output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the frequency at which we will check whether Textract asynchronous job has been completed\n",
    "sleep_time = 5\n",
    "\n",
    "# function to start a Textract Document Text Detection job (asynchronous)\n",
    "# note that for documents with more than 1 page, we need to run Textract asynchronously\n",
    "def StartDocumentTextDetection(s3BucketName, objectName):\n",
    "    response = None\n",
    "    client = boto3.client('textract')\n",
    "    response = client.start_document_text_detection(\n",
    "        DocumentLocation={\n",
    "            'S3Object': {\n",
    "                'Bucket': s3BucketName,\n",
    "                'Name': objectName\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    return response[\"JobId\"]\n",
    "\n",
    "# function to check whether Textract asynchronous job has been completed\n",
    "def isJobComplete(jobId):\n",
    "    # For production use cases, use SNS based notification \n",
    "    # Details at: https://docs.aws.amazon.com/textract/latest/dg/api-async.html\n",
    "    time.sleep(sleep_time)\n",
    "    client = boto3.client('textract')\n",
    "    response = client.get_document_text_detection(JobId=jobId)\n",
    "    status = response[\"JobStatus\"]\n",
    "    #print(\"Job status: {}\".format(status))\n",
    "\n",
    "    while (status == \"IN_PROGRESS\"):\n",
    "        time.sleep(sleep_time)\n",
    "        response = client.get_document_text_detection(JobId=jobId)\n",
    "        status = response[\"JobStatus\"]\n",
    "        #print(\"Job status: {}\".format(status))\n",
    "\n",
    "    return status\n",
    "\n",
    "# function to collect detected text from all pages of the document\n",
    "def getDocumentTextDetectionResults(jobId):\n",
    "    pages = []\n",
    "    client = boto3.client('textract')\n",
    "    response = client.get_document_text_detection(JobId=jobId)\n",
    " \n",
    "    pages.append(response)\n",
    "    #print(\"Resultset page recieved: {}\".format(len(pages)))\n",
    "    nextToken = None\n",
    "    if('NextToken' in response):\n",
    "        nextToken = response['NextToken']\n",
    "    while(nextToken):\n",
    "        response = client.get_document_text_detection(JobId=jobId, NextToken=nextToken)\n",
    "        pages.append(response)\n",
    "        #print(\"Resultset page recieved: {}\".format(len(pages)))\n",
    "        nextToken = None\n",
    "        if('NextToken' in response):\n",
    "            nextToken = response['NextToken']\n",
    "    \n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# get list of input files\n",
    "pdf_object_list = []\n",
    "response = s3_client.list_objects(\n",
    "    Bucket= input_bucket,\n",
    "    Prefix= input_prefix\n",
    ")\n",
    "\n",
    "for obj in response['Contents']:\n",
    "    if obj['Size']!=0:\n",
    "        pdf_object_list.append(obj['Key'])\n",
    "\n",
    "pdf_object_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\" Submitting file to Textract for Processing\")\n",
    "def f(file_obj):\n",
    "    #print('Textract Processing JPG: \\t'+ file_obj)             \n",
    "    job_id = StartDocumentTextDetection(input_bucket, file_obj)\n",
    "    #print('Textract Job Submitted: \\t'+ job_id)\n",
    "    status = isJobComplete(job_id)\n",
    "    if status=='SUCCEEDED':\n",
    "        response = getDocumentTextDetectionResults(job_id)\n",
    "    #print (response)\n",
    "        \n",
    "    \n",
    "    # renaming .pdf to .text\n",
    "    random_string = str(random.random())\n",
    "    text_output_name = file_obj.replace('.jpg', f\"{random_string}.csv\")\n",
    "    text_output_name = text_output_name[(text_output_name.rfind('/')+1):]\n",
    "    #print('Output Name:\\t', text_output_name)\n",
    "    \n",
    " \n",
    "    \n",
    "    # Writing Textract Output to Text Files:\n",
    "    with codecs.open(text_output_name, \"w\", \"utf-8\") as output_file:\n",
    "        for resultPage in response:\n",
    "            for item in resultPage[\"Blocks\"]:\n",
    "                if item[\"BlockType\"] == \"WORD\":\n",
    "                    #print('\\033[94m' + item[\"Text\"] + '\\033[0m')\n",
    "                    output_file.write(item[\"Text\"]+'\\n')\n",
    "    output_file.close()\n",
    "    \n",
    "    try:\n",
    "        s3_client.upload_file(text_output_name, output_bucket, \n",
    "                              output_prefix+text_output_name)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Exception message from S3 buckets upload: {}\".format(str(e)))\n",
    "\n",
    " \n",
    "with Pool(5) as p:\n",
    "    p.map(f, pdf_object_list)\n",
    "\n",
    "print(\"Textract Processing Completed\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
